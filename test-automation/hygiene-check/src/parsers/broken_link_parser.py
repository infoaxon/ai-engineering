"""Parser for broken link checker output (check-broken-links.sh / linkinator)."""

from __future__ import annotations

import csv
import io
import json
import logging
import re

from ..models import BrokenLinkItem, LinkState
from ..utils.shell import strip_ansi

logger = logging.getLogger(__name__)

# Phase 1 line patterns (after ANSI stripping)
# Emojis followed by status code and slug
STATUS_LINE_RE = re.compile(r"^\s*\S+\s+(\d{3}|TIMEOUT)\s+(.+?)(?:\s+â†’\s+(.+))?$")

# Summary counters
COUNTER_RE = re.compile(r"^\s*([\w\s/()]+):\s+(\d+)")

# Report path
CSV_REPORT_RE = re.compile(r"CSV Report:\s*(.+\.csv)")
JSON_REPORT_RE = re.compile(r"JSON Report:\s*(.+\.json)")


def _status_to_link_state(code_str: str) -> LinkState:
    if code_str == "TIMEOUT":
        return LinkState.TIMEOUT
    code = int(code_str)
    if code == 200:
        return LinkState.OK
    elif 300 <= code < 400:
        return LinkState.REDIRECTED
    else:
        return LinkState.BROKEN


def parse_console_output(raw_output: str) -> dict:
    """Parse the console output of check-broken-links.sh.

    Returns dict with keys: links, ok_count, broken_count, redirected_count, timeout_count,
    csv_path, json_path
    """
    output = strip_ansi(raw_output)
    links: list[BrokenLinkItem] = []
    ok_count = broken_count = redirected_count = timeout_count = 0
    csv_path = json_path = ""

    for line in output.splitlines():
        stripped = line.rstrip()

        # Status line match
        m = STATUS_LINE_RE.match(stripped)
        if m:
            code_str, slug, redirect = m.group(1), m.group(2).strip(), m.group(3)
            state = _status_to_link_state(code_str)
            links.append(BrokenLinkItem(
                url=slug,
                status_code=int(code_str) if code_str != "TIMEOUT" else None,
                link_state=state,
            ))
            continue

        # Report paths
        csv_m = CSV_REPORT_RE.search(stripped)
        if csv_m:
            csv_path = csv_m.group(1).strip()
            continue

        json_m = JSON_REPORT_RE.search(stripped)
        if json_m:
            json_path = json_m.group(1).strip()
            continue

    # Count by state
    for link in links:
        if link.link_state == LinkState.OK:
            ok_count += 1
        elif link.link_state == LinkState.BROKEN:
            broken_count += 1
        elif link.link_state == LinkState.REDIRECTED:
            redirected_count += 1
        elif link.link_state == LinkState.TIMEOUT:
            timeout_count += 1

    return {
        "links": links,
        "ok_count": ok_count,
        "broken_count": broken_count,
        "redirected_count": redirected_count,
        "timeout_count": timeout_count,
        "csv_path": csv_path,
        "json_path": json_path,
    }


def parse_json_report(json_path: str) -> list[BrokenLinkItem]:
    """Parse the JSON report file generated by check-broken-links.sh."""
    try:
        with open(json_path) as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        logger.warning(f"Could not parse JSON report {json_path}: {e}")
        return []

    links = []
    for entry in data:
        code = entry.get("status")
        code_str = str(code) if code else "TIMEOUT"
        links.append(BrokenLinkItem(
            url=entry.get("url", ""),
            status_code=code if isinstance(code, int) else None,
            link_state=_status_to_link_state(code_str),
            response_ms=entry.get("responseMs"),
        ))
    return links


def calculate_score(ok: int, broken: int, redirected: int, timeout: int) -> float:
    """Calculate broken links score (0-100)."""
    total = ok + broken + redirected + timeout
    if total == 0:
        return 100.0
    # broken links are heavy deductions; redirects and timeouts are minor
    deduction = (broken * 10) + (timeout * 3) + (redirected * 0.5)
    return max(0.0, min(100.0, 100.0 - deduction))
